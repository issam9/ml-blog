<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://issam9.github.io/ml-blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://issam9.github.io/ml-blog/" rel="alternate" type="text/html" /><updated>2022-07-28T10:18:04-05:00</updated><id>https://issam9.github.io/ml-blog/feed.xml</id><title type="html">issamâ€™s blog</title><entry><title type="html">Pretraining is all you need</title><link href="https://issam9.github.io/ml-blog/nlp/pretraining/2022/07/28/pretraining.html" rel="alternate" type="text/html" title="Pretraining is all you need" /><published>2022-07-28T00:00:00-05:00</published><updated>2022-07-28T00:00:00-05:00</updated><id>https://issam9.github.io/ml-blog/nlp/pretraining/2022/07/28/pretraining</id><author><name></name></author><category term="NLP" /><category term="Pretraining" /><summary type="html">Finetuning a pretrained language model is the way to go when tackling most if not all NLP tasks. After a model is pretrained, it can be adapted for multiple tasks by adding a few task-dependent layers and training for a few iterations. Fine-tuned models usually show interesting generalization abilities and stability over models trained from scratch. These qualities have closed the gap between finetuning a PLM model directly and using regularization or noise-handling techniques. In this blog, we will discuss some of these techniques and the papers that questioned their effectiveness.</summary></entry><entry><title type="html">Finetuning DziriBERT for Dialect Detection</title><link href="https://issam9.github.io/ml-blog/2021/10/19/Finetune-DziriBERT.html" rel="alternate" type="text/html" title="Finetuning DziriBERT for Dialect Detection" /><published>2021-10-19T00:00:00-05:00</published><updated>2021-10-19T00:00:00-05:00</updated><id>https://issam9.github.io/ml-blog/2021/10/19/Finetune-DziriBERT</id><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Building a language model for Moroccan Darija using fastai</title><link href="https://issam9.github.io/ml-blog/2021/08/30/Darija-LM.html" rel="alternate" type="text/html" title="Building a language model for Moroccan Darija using fastai" /><published>2021-08-30T00:00:00-05:00</published><updated>2021-08-30T00:00:00-05:00</updated><id>https://issam9.github.io/ml-blog/2021/08/30/Darija-LM</id><author><name></name></author><summary type="html"></summary></entry></feed>