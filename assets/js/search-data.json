{
  
    
        "post0": {
            "title": "Title",
            "content": "This is a small effort to build a darija language model, i use Moroccan Darija Wikipedia to train an AWD_LSTM model using fastai, it is a small dataset which means that this language model won&#39;t be perfect for language generation but it might be useful to finetune it on a task like text classification following the ULMFiT approach, where you train a language model on Wikipedia text like we do in this notebook to gain some knowledge about the language of your choice, then finetune it on domain-specific data using the same objective of your pretrained language model, to bridge the gap between the language used in wikipedia text and the language used in your dataset(e.g., formal language -&gt; informal language), and finally, we finetune our language model on our task of text classification. . This model can be improved by: . Throwing more data at it of course | Some text preprocessing | Tuning the hyperparameters | I thought also about pretraining on arabic which might be a good idea given the similarities between arabic and darija | . . Let&#39;s start by upgrading fastai and installing SentencePiece to use for subword tokenization . !pip install fastai -q --upgrade !pip install -q sentencepiece!=0.1.90,!=0.1.91 . import sys from gensim.corpora import WikiCorpus from fastai.text.all import * import torch as torch import pandas as pd import numpy as np . from google.colab import drive drive.mount(&#39;/content/drive/&#39;) . Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(&#34;/content/drive/&#34;, force_remount=True). . path = Path(&#39;/content/drive/MyDrive/ml/projects/darija/&#39;) dls_path = path/&#39;dls&#39; model_path = path/&#39;models&#39; spm_path = model_path/&#39;spm&#39; dls_path.mkdir(exist_ok=True, parents=True) model_path.mkdir(exist_ok=True, parents=True) spm_path.mkdir(exist_ok=True, parents=True) . This is how we can download The Moroccan Darija Wikipedia data, it&#39;s available in this link . !wget https://dumps.wikimedia.org/arywiki/latest/arywiki-latest-pages-articles.xml.bz2 -O &#39;/content/drive/MyDrive/ml/projects/darija/arywiki-latest-pages-articles.xml.bz2&#39; . --2021-08-28 19:55:19-- https://dumps.wikimedia.org/arywiki/latest/arywiki-latest-pages-articles.xml.bz2 Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7 Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 4178623 (4.0M) [application/octet-stream] Saving to: โ/content/drive/MyDrive/ml/projects/darija/arywiki-latest-pages-articles.xml.bz2โ /content/drive/MyDr 100%[===================&gt;] 3.98M 5.61MB/s in 0.7s 2021-08-28 19:55:20 (5.61 MB/s) - โ/content/drive/MyDrive/ml/projects/darija/arywiki-latest-pages-articles.xml.bz2โ saved [4178623/4178623] . We make use of WikiCorpus from gensim to convert the XML file we downloaded to a text corpus. . def make_corpus(in_f, out_f): &quot;&quot;&quot;Convert Wikipedia xml dump file to text corpus&quot;&quot;&quot; output = open(out_f, &#39;w&#39;) wiki = WikiCorpus(in_f) for i, text in enumerate(wiki.get_texts()): output.write(bytes(&#39; &#39;.join(text), &#39;utf-8&#39;).decode(&#39;utf-8&#39;) + &#39; n&#39;) if (i % 1000 == 0): print(&#39;Processed &#39; + str(i) + &#39; articles&#39;) output.close() print(&#39;Processing complete!&#39;) make_corpus(f&#39;{path}/arywiki-latest-pages-articles.xml.bz2&#39;, f&#39;{path}/wiki_darija.txt&#39;) . Processed 0 articles Processed 1000 articles Processed 2000 articles Processed 3000 articles Processing complete! . path.ls() . (#10) [Path(&#39;/content/drive/MyDrive/ml/projects/darija/arwiki.xml.bz2&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/dls&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/models&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/arwiki-latest-pages-articles.xml.bz2&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/wiki_arabic.txt&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/Untitled0.ipynb&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/Copie de darija_lm.ipynb&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/arywiki-latest-pages-articles.xml.bz2&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/wiki_darija.txt&#39;),Path(&#39;/content/drive/MyDrive/ml/projects/darija/darija_lm.ipynb&#39;)] . Now we load our text data as a pandas dataframe, and we take a look at it using the most advanced EDA technique ๐, we can see that there are words from other languages that will most likely disappear due to their low frequency, and we can tell fastai the minimum word frequency (by default itโs 3) we can tolerate using fastai DataBlocks that we discuss below. . df = pd.read_csv(path/&#39;wiki_darija.txt&#39;, header=None, names=[&#39;text&#39;]) df.head() . text . 0 ุขุจุทุญ ุฌูุงุนุฉ ุชุฑุงุจูุฉ ูุฑููุฉ ูุงููุฉ ุฅูููู ุนูุงูุฉ ุทุงู ุทุงู ุฌูุฉ ฃูููู ูุงุฏ ููู ุณุงูููู ูููุง ูุงุญุฏ ุนูู ุญุณุจ ูุฅุญุตุงุก ูุนุงู ุชุนููู ูุณุจุฉ ูุฃููุฉ ุงุณ ูุง ูุงูุนุฑููุด ููุฑุงู ููุง ููุชุจู ูุณุจุฉ ูุงู ูุงุฑููู ููู ุงููู ุชุงููู ุฌุงูุนุฉ ุงูุชุตุงุฏ ูุณุจุฉ ุงุณ ุดูุทูู ููุฏุฑู ูุฎุฏูู ูุณุจุฉ ูุจุทุงูุฉ ุงุณ ูุง ุฎุฏุงูููุด ุชุงูููุจู ุนูู ุฎุฏูุฉ ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ููุฉ ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ูู ููุทุงุน ูุฎุงุต ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ุนููู ูููุงู ุชุตููู ุฌูุฉ ฃูููู ูุงุฏ ููู | . 1 ุขุณูู ุจุงูุฃูุงุฒูุบูุฉ โดฐโตโดผโต ูู ูุฏููุฉ ูุบุฑุจูุฉ ุฌุงุช ุฅูููู ุขุณูู ุฌูุฉ ูุฑุงูุด ุขุณูู ุขุณูู ูุนุฑููุฉ ุจุงููุฎุงุฑ ูุงูุญูุช ูุฎุตูุตุง ุงูุณุฑุฏูู ููููููู ุนูููุง ุญุงุถุฑุฉ ุงููุญูุท ุงูุญุทุฉ ุฏูุงู ุขุณูู ุฌุงุช ูุงุทู ุนูู ุงููุญูุท ุงูุฃุทูุณู ุจูู ุงูุฌุฏูุฏุฉ ูุงูุตููุฑุฉ ูู ุขุณูู ูุงูู ุจุฒุงู ุฏุงูุจูู ูู ูุฏูู ูุชุงุฑูุฎู ููู ูู ุจูู ุงููุฏูู ุงููุฏููุฉ ูู ุงููุบุฑุจ ุณุงูููู ูููุง ูุงุญุฏ ุนูู ุญุณุจ ูุฅุญุตุงุก ูุนุงู ุชุนููู ูุณุจุฉ ูุฃููุฉ ุงุณ ูุง ูุงูุนุฑููุด ููุฑุงู ููุง ููุชุจู ูุณุจุฉ ูุงู ูุงุฑููู ููู ุงููู ุชุงููู ุฌุงูุนุฉ ุงูุชุตุงุฏ ูุณุจุฉ ุงุณ ุดูุทูู ููุฏุฑู ูุฎุฏูู ูุณุจุฉ ูุจุทุงูุฉ ุงุณ ูุง ุฎุฏุงูููุด ุชุงูููุจู ุนูู ุฎุฏูุฉ ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ููุฉ ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ูู ููุทุงุน ูุฎุงุต ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏ... | . 2 ุขูุจุฑุฎุช ุฏูุฑุฑ ุจุงูุฃููุงููุฉ albrecht dรผrer ูุงู ุฃุจุฑูู ุฑุณุงู ุตุงูุน ุทุจุงุนุฉ ูู ูุงููุชุงูู ูุนุตุฑ ุงูููุถุฉ ุงูุฃููุงููุฉ ุชุฒุงุฏ ูู ููุฑูุจุฑฃ ุฏูุฑุฑ ุฃุณุณ ููุณูุนุฉ ูุงูุชุฃุซูุฑ ุฏูุงูู ุนุจุฑ ุฃูุฑูุจุง ูุงูููุช ุงููู ูุงุฒุงูุง ูุงูุนุดุฑููุงุช ูู ุนูุฑู ูุชูุฌุฉ ูุฌูุฏุฉ ูููุดุงุชู ุงูุฎุดุจูุฉ ูุงู ูุงุชุตุงู ูุน ุฃูุจุฑ ุงูููุงููู ุงูุฅูุทุงูููู ูุงูุนุตุฑ ุฏูุงูู ุจูุง ูููู ุฑูุงุฆูู ุฌููฺคุงูู ุจููููู ูููููุงุฑุฏู ุฏุง ฺคููุชุดู ูุงุจุชุฏุงุก ูู ูุงู ูู ุงุฎุฏ ุงูุฏุนู ูู ุนูุฏ ุงูุฅูุจุฑุงุทูุฑ ูุงูุณูููููุงู ุงูุฃูู ุชู ุชุดููุน ุฏูุฑุฑ ูุงููููุณุชูู ุงูููุซุฑูุฉ ูุงูุฃุณูููุฉ ุจุฌูุฌ ูุชุดูู ูุฌููุนุฉ ุฃุนูุงู ุฏูุฑุฑ ุงููุงุณุนุฉ ุงููููุด ุฃุณููุจู ุงูููุถู ูู ุทุจุนุงุชู ุงูุฃุฎูุฑุฉ ุงูุฃุนูุงู ุงููููุฉ ูุงูููุงุฆุณ altarpieces ูพูุฑุชุฑููุงุช ูพูุฑุชุฑููุงุช ุฐุงุชูุฉ ููุญุงุช ูุงุฆูุฉ ูู ุงููููุด ุงูุฎ... | . 3 ุขูุชุฏู ุฌูุงุนุฉ ุชุฑุงุจูุฉ ูุฑููุฉ ูุงููุฉ ุฅูููู ุนูุงูุฉ ฃูููู ุฌูุฉ ฃูููู ูุงุฏ ููู ุณุงูููู ูููุง ูุงุญุฏ ุนูู ุญุณุจ ูุฅุญุตุงุก ูุนุงู ุชุนููู ูุณุจุฉ ูุฃููุฉ ุงุณ ูุง ูุงูุนุฑููุด ููุฑุงู ููุง ููุชุจู ูุณุจุฉ ูุงู ูุงุฑููู ููู ุงููู ุชุงููู ุฌุงูุนุฉ ุงูุชุตุงุฏ ูุณุจุฉ ุงุณ ุดูุทูู ููุฏุฑู ูุฎุฏูู ูุณุจุฉ ูุจุทุงูุฉ ุงุณ ูุง ุฎุฏุงูููุด ุชุงูููุจู ุนูู ุฎุฏูุฉ ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ููุฉ ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ูู ููุทุงุน ูุฎุงุต ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ุนููู ูููุงู ุชุตููู ุฌูุฉ ฃูููู ูุงุฏ ููู | . 4 ุขููฃ ุฌูุงุนุฉ ุชุฑุงุจูุฉ ูุฑููุฉ ูุงููุฉ ุฅูููู ุนูุงูุฉ ุณูุฏู ุฅูููู ุฌูุฉ ฃูููู ูุงุฏ ููู ุณุงูููู ูููุง ูุงุญุฏ ุนูู ุญุณุจ ูุฅุญุตุงุก ูุนุงู ุชุนููู ูุณุจุฉ ูุฃููุฉ ุงุณ ูุง ูุงูุนุฑููุด ููุฑุงู ููุง ููุชุจู ูุณุจุฉ ูุงู ูุงุฑููู ููู ุงููู ุชุงููู ุฌุงูุนุฉ ุงูุชุตุงุฏ ูุณุจุฉ ุงุณ ุดูุทูู ููุฏุฑู ูุฎุฏูู ูุณุจุฉ ูุจุทุงูุฉ ุงุณ ูุง ุฎุฏุงูููุด ุชุงูููุจู ุนูู ุฎุฏูุฉ ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ููุฉ ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ูู ููุทุงุน ูุฎุงุต ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ุนููู ูููุงู ุชุตููู ุฌูุฉ ฃูููู ูุงุฏ ููู | . Subword tokenization refers to constructing our vocabulary using the most frequently occurring groups of letters, for instance, the word โtransformerโ could be split into โtransโ and โformerโ. I find it better to use subword tokenization with a relatively smaller vocabulary size in the case of a small dataset, to avoid the p&gt;&gt;n problem (where the number of features exceeds the number of training examples), and also because if we decide to use words as our tokens, we are going to have a lot of words that appear only a few times throughout the corpus, and the model wonโt be given a decent chance to learn about them. . I use a maximum vocab size (max_vocab_sz) of 1000 but you can use less or more, its another hyperparamter you can tune based on the metric you care about. . The data block API is provided by fastai to customize the creation of our dataloaders, blocks parameter is used to specify the type of our independent and dependent variables, when TextBlock is passed, fastai takes care of preprocessing for us, we just need to pass it our subword tokenizer since it uses word tokenization by default, we also tell fastai that we are building this for a language modeling with is_lm and that our text is in a dataframe. . And finally we create our dataloaders, it&#39;s a dataloader with s because it includes the training and validation dataloaders. . bs=128 tok = SubwordTokenizer(cache_dir=spm_path, max_vocab_sz=10_00) dls_lm = DataBlock(blocks=TextBlock.from_df(&#39;text&#39;, is_lm=True, tok=tok), splitter=RandomSplitter(0.1, seed=42), get_x=ColReader(&#39;text&#39;) ).dataloaders(df, bs=bs) . /usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray return array(a, dtype, copy=False, order=order) . We save our dataloader since we can&#39;t afford to create it each time because of our huge dataset. . torch.save(dls_lm, dls_path/&#39;dls_lm.pkl&#39;) . This is how our preprocessed text looks like, spaces in the original text are replaced by โ, xxbos is a special token added by fastai to signify the beginning of a sentence, fastai also adds other special tokens to make learning easier for the model, we can see them when we check our vocab below. . dls_lm.show_batch(max_n=6) . text text_ . 0 โxxbos โูุฃุนุถ ุงุก โููุถู ุฉ โุงูุชุนุงูู โุดุงูฃ ุงู โูููุถู ุฉ โุงูุชุนุงูู โุดุงูฃ ุงู โูู โููุถู ุฉ โุฏูููุฉ โุณูุงุณูุฉ โูุชุตุงุฏ ูุฉ โุฃูู ูุฉ โุชุฃุณุณ ุงุช โููุงุฑ โ ููููู โุดุงูฃ ุงู โูู โูุจูุฏุงู โูู โุงูุดูููุง โูุงุฒุงุฎ ุณุชุงู โ ููุฑฃู ุณุชุงู โุฑูุณูุง โ ุทุงุฏุฌููู ุณุชุงู โุฃูุฒุจุงู ุณุชุงู โูุงุฏ โูุจูุฏุงู โูุงูู ุฉ โูู โุบูุฑ โุฃูุฒุจุงู ุณุชุงู โูุงูุช โุฏุงุฎู ุฉ โูุน โูุฌููุน ุฉ โุดุงูฃ ุงู โูุฎ ูุงุณ ูุฉ โุงููู โุชุฃุณุณ ุงุช โุฃุจุฑ ูู โุดุงูฃ ุงู โููุช โูู | โูุฃุนุถ ุงุก โููุถู ุฉ โุงูุชุนุงูู โุดุงูฃ ุงู โูููุถู ุฉ โุงูุชุนุงูู โุดุงูฃ ุงู โูู โููุถู ุฉ โุฏูููุฉ โุณูุงุณูุฉ โูุชุตุงุฏ ูุฉ โุฃูู ูุฉ โุชุฃุณุณ ุงุช โููุงุฑ โ ููููู โุดุงูฃ ุงู โูู โูุจูุฏุงู โูู โุงูุดูููุง โูุงุฒุงุฎ ุณุชุงู โ ููุฑฃู ุณุชุงู โุฑูุณูุง โ ุทุงุฏุฌููู ุณุชุงู โุฃูุฒุจุงู ุณุชุงู โูุงุฏ โูุจูุฏุงู โูุงูู ุฉ โูู โุบูุฑ โุฃูุฒุจุงู ุณุชุงู โูุงูุช โุฏุงุฎู ุฉ โูุน โูุฌููุน ุฉ โุดุงูฃ ุงู โูุฎ ูุงุณ ูุฉ โุงููู โุชุฃุณุณ ุงุช โุฃุจุฑ ูู โุดุงูฃ ุงู โููุช โูู โุฏุงุจ | . 1 โุฎุช ูุง โุฒู ุงุฏุง ุชุงู โูุดู โุฃููุงู โุณูููุงุฆู ุฉ โุนููู โูููุงู โุชุตููู โููุชู ุฉ โูุบุฑูุจูุฉ โxxbos โูุญูุฏ โูุดุง ูู โุชุฒุงุฏ โุชูู ู โููููู ุฒ โูู โุทุจูุจ โูุตุฑู โูุชุฎุตุต โุทุจ โูุจุงุท ูู โู ุชุนุฑู โุทุจูุจ โูููุฑ ุงุก โฃ ุฑุงู ูุชู โูุฏูู ุฉ โููุญูุฏู ุฉ โููุบุฑูุจ โุฏุงุฑูู โูุฌููุน ุฉ โูู โุดุจุงุจ โุชูุฑูู ุง โุทุจูุจ โููุตุฑู โูุญูุฏ โูุดุง ูู โูุดุฑุงุช ู โ ุฌุฑูุฏ ุฉ โุงู ุนูู โููุฑุงู ุฉ โุชุฒุงุฏ โูุญูุฏ โูุดุง ูู โูุญุงูุถ ุฉ โูุจุญ | ูุง โุฒู ุงุฏุง ุชุงู โูุดู โุฃููุงู โุณูููุงุฆู ุฉ โุนููู โูููุงู โุชุตููู โููุชู ุฉ โูุบุฑูุจูุฉ โxxbos โูุญูุฏ โูุดุง ูู โุชุฒุงุฏ โุชูู ู โููููู ุฒ โูู โุทุจูุจ โูุตุฑู โูุชุฎุตุต โุทุจ โูุจุงุท ูู โู ุชุนุฑู โุทุจูุจ โูููุฑ ุงุก โฃ ุฑุงู ูุชู โูุฏูู ุฉ โููุญูุฏู ุฉ โููุบุฑูุจ โุฏุงุฑูู โูุฌููุน ุฉ โูู โุดุจุงุจ โุชูุฑูู ุง โุทุจูุจ โููุตุฑู โูุญูุฏ โูุดุง ูู โูุดุฑุงุช ู โ ุฌุฑูุฏ ุฉ โุงู ุนูู โููุฑุงู ุฉ โุชุฒุงุฏ โูุญูุฏ โูุดุง ูู โูุญุงูุถ ุฉ โูุจุญ ูุฑ | . 2 โ ูุญุงูู ุฉ โุนุงุฏู ุฉ โูุญู โูุญุฑู ุฉ โุงูุชุนุจูุฑ โูุญู โูุญุจุงุณ ุฉ โุงูุช ุทุจูุจ โุถุฑูู โูุฒูุงู ุฉ โู ุญุจุณ โูุญู โุงู ุชูุธูู โุฌ ุช ูุงุน ุงุช โุนููู โูููุงู โููุฒุง ูุฏ โูู ููุน โุฏูุงู โูุฌูุนู ุฉ โููุบุฑุจู ุฉ โูุญููู โูุฅูุณุงู โุชุตููู โุญููู โูุฅูุณุงู โุชุตููู โุฌูุนู ุฉ โูุบุฑูุจูุฉ โxxbos โุขฃุฏ ุฒ โุฌูุงุน ุฉ โุชุฑุงุจูุฉ โุญุถุฑู ุฉ โูุงูู ุฉ โุฅูููู โุนูุงู ุฉ โุฒุงฃูุฑ ุฉ โุฌู ุฉ โุฏุฑุน ุง โุชุงูููุงูุช โุณุงูููู โูููุง โูุงุญุฏ โุนู ู โุญุณุจ | ูุญุงูู ุฉ โุนุงุฏู ุฉ โูุญู โูุญุฑู ุฉ โุงูุชุนุจูุฑ โูุญู โูุญุจุงุณ ุฉ โุงูุช ุทุจูุจ โุถุฑูู โูุฒูุงู ุฉ โู ุญุจุณ โูุญู โุงู ุชูุธูู โุฌ ุช ูุงุน ุงุช โุนููู โูููุงู โููุฒุง ูุฏ โูู ููุน โุฏูุงู โูุฌูุนู ุฉ โููุบุฑุจู ุฉ โูุญููู โูุฅูุณุงู โุชุตููู โุญููู โูุฅูุณุงู โุชุตููู โุฌูุนู ุฉ โูุบุฑูุจูุฉ โxxbos โุขฃุฏ ุฒ โุฌูุงุน ุฉ โุชุฑุงุจูุฉ โุญุถุฑู ุฉ โูุงูู ุฉ โุฅูููู โุนูุงู ุฉ โุฒุงฃูุฑ ุฉ โุฌู ุฉ โุฏุฑุน ุง โุชุงูููุงูุช โุณุงูููู โูููุง โูุงุญุฏ โุนู ู โุญุณุจ โู | . 3 โุชุงูู ูุจู โุนู ู โุฎุฏู ุฉ โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู โูู ุฉ โููุง โูุนุงุท ููู โุงููู โุณุจู โู ูููู โุฎุฏูู โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู โูู โููุทุงุน โูุฎุงุต โููุง โูุนุงุท ููู โุงููู โุณุจู โู ูููู โุฎุฏูู โุนููู โูููุงู โุชุตููู โุฌู ุฉ โุงูุฑุจุงุท โุณูุง โุงููููุทุฑุฉ โxxbos โูพูู ูู โูุง โุจ ูุฌูู ฃ โุงูุดูููู ุฉ โ ๅ ไบฌ โูู โู ุนุงุตู ุฉ โุฏูุงู โุงูุดูููุง โุชุงูู โุฃูุจ ุฑ โูุฏูู ุฉ โูููุง โููุฑุง โุดุงูฃ ูุงู โูพูู ูู | ูุจู โุนู ู โุฎุฏู ุฉ โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู โูู ุฉ โููุง โูุนุงุท ููู โุงููู โุณุจู โู ูููู โุฎุฏูู โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู โูู โููุทุงุน โูุฎุงุต โููุง โูุนุงุท ููู โุงููู โุณุจู โู ูููู โุฎุฏูู โุนููู โูููุงู โุชุตููู โุฌู ุฉ โุงูุฑุจุงุท โุณูุง โุงููููุทุฑุฉ โxxbos โูพูู ูู โูุง โุจ ูุฌูู ฃ โุงูุดูููู ุฉ โ ๅ ไบฌ โูู โู ุนุงุตู ุฉ โุฏูุงู โุงูุดูููุง โุชุงูู โุฃูุจ ุฑ โูุฏูู ุฉ โูููุง โููุฑุง โุดุงูฃ ูุงู โูพูู ูู โูู | . 4 โูุงูู ูู โูุน ู โุฑูู โุฃ ุฌูุฒ ุฉ โููุฑุงูุจ ุฉ โู ุญุถ ูุฉ โูุฎู โููุจูุฑ โุนู โุฑู โูุง โูุงูุจุงู โุฏููุง โูุงูุช ุต ู โูุฌู โุฑุงุฌู โุนูุฏู โุนุงู โู ุงุบ ู โูุงูุดูู โูุนูููู โ ููุดุงู โูุงุญุฏ โูู โูุงู ุฑ ูุจ โุนู ู โุญุณุงุจ โููุงู ุฉ โุณูู ุฉ โูุฎู โููุจูุฑ โูู โุฃุณ โูุญู ุฒุจ โููุญูุฏ โูุจูุงุฏ โุนูุฏู โุจุฒ โุงู โูุจูุทูู ุงุช โูุฅูุฌุงุฒ ุงุช โุงูุซูุฑ ูุฉ โูุญุฑุจ ูุฉ โููุถู ุฉ โุฏูุงู โุฃูู โูุงูุจูุง โุฏููุง โุตุบูุฑ | ูู โูุน ู โุฑูู โุฃ ุฌูุฒ ุฉ โููุฑุงูุจ ุฉ โู ุญุถ ูุฉ โูุฎู โููุจูุฑ โุนู โุฑู โูุง โูุงูุจุงู โุฏููุง โูุงูุช ุต ู โูุฌู โุฑุงุฌู โุนูุฏู โุนุงู โู ุงุบ ู โูุงูุดูู โูุนูููู โ ููุดุงู โูุงุญุฏ โูู โูุงู ุฑ ูุจ โุนู ู โุญุณุงุจ โููุงู ุฉ โุณูู ุฉ โูุฎู โููุจูุฑ โูู โุฃุณ โูุญู ุฒุจ โููุญูุฏ โูุจูุงุฏ โุนูุฏู โุจุฒ โุงู โูุจูุทูู ุงุช โูุฅูุฌุงุฒ ุงุช โุงูุซูุฑ ูุฉ โูุญุฑุจ ูุฉ โููุถู ุฉ โุฏูุงู โุฃูู โูุงูุจูุง โุฏููุง โุตุบูุฑ โุณุจ | . 5 ุฉ โุชูู ุบูุฑ โุฌู ุฉ โุฏุฑุน ุง โุชุงูููุงูุช โุณุงูููู โูููุง โูุงุญุฏ โุนู ู โุญุณุจ โู ุฅุญุตุงุก โูุนุงู โุชุนููู โูุณุจุฉ โูุฃูู ุฉ โุงุณ โูุง โูุงูุนุฑูู ุด โููุฑุง ู โููุง โููุชุจ ู โูุณุจุฉ โูุงู โ ูุงุฑููู โููู โ ุงููู โุชุงููู โุฌุงูุน ุฉ โุงูุชุตุงุฏ โูุณุจุฉ โุงุณ โุดูุท ูู โ ููุฏุฑู โ ูุฎุฏูู โูุณุจุฉ โูุจุทุงู ุฉ โุงุณ โูุง โุฎุฏุงููู ุด โุชุงูู ูุจู โุนู ู โุฎุฏู ุฉ โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู โูู ุฉ โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู | โุชูู ุบูุฑ โุฌู ุฉ โุฏุฑุน ุง โุชุงูููุงูุช โุณุงูููู โูููุง โูุงุญุฏ โุนู ู โุญุณุจ โู ุฅุญุตุงุก โูุนุงู โุชุนููู โูุณุจุฉ โูุฃูู ุฉ โุงุณ โูุง โูุงูุนุฑูู ุด โููุฑุง ู โููุง โููุชุจ ู โูุณุจุฉ โูุงู โ ูุงุฑููู โููู โ ุงููู โุชุงููู โุฌุงูุน ุฉ โุงูุชุตุงุฏ โูุณุจุฉ โุงุณ โุดูุท ูู โ ููุฏุฑู โ ูุฎุฏูู โูุณุจุฉ โูุจุทุงู ุฉ โุงุณ โูุง โุฎุฏุงููู ุด โุชุงูู ูุจู โุนู ู โุฎุฏู ุฉ โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู โูู ุฉ โูุณุจุฉ โุงุณ โุงููู โุฎุฏุงููู โูู | . print(dls_lm.vocab[:20]) . [&#39;xxunk&#39;, &#39;xxpad&#39;, &#39;xxbos&#39;, &#39;xxeos&#39;, &#39;xxfld&#39;, &#39;xxrep&#39;, &#39;xxwrep&#39;, &#39;xxup&#39;, &#39;xxmaj&#39;, &#39;ุฉ&#39;, &#39;โ&#39;, &#39;โู&#39;, &#39;ู&#39;, &#39;โุฏูุงู&#39;, &#39;โุงู&#39;, &#39;โุงููู&#39;, &#39;ุงุช&#39;, &#39;ุง&#39;, &#39;โูุณุจุฉ&#39;, &#39;โูู&#39;] . learn = language_model_learner(dls_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], pretrained=False) . /usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:120: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available. Disabling. warnings.warn(&#34;torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available. Disabling.&#34;) . learn.lr_find() . /usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available. Disabling. warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available. Disabling.&#34;) . . 0.00% [0/5 00:00&lt;00:00] . 0.00% [0/24 00:00&lt;00:00] learn.unfreeze() learn.fit_one_cycle(100, 1e-2) . epoch train_loss valid_loss accuracy perplexity time . 0 | 5.834657 | 5.780706 | 0.050297 | 323.987976 | 00:27 | . 1 | 5.786645 | 5.777408 | 0.046491 | 322.920990 | 00:27 | . 2 | 5.771509 | 5.716337 | 0.057275 | 303.790161 | 00:26 | . 3 | 5.335208 | 5.050761 | 0.110819 | 156.141281 | 00:26 | . 4 | 4.643136 | 4.369634 | 0.198885 | 79.014679 | 00:26 | . 5 | 4.215887 | 4.142004 | 0.225452 | 62.928776 | 00:26 | . 6 | 3.989751 | 3.972366 | 0.243707 | 53.110031 | 00:26 | . 7 | 3.835457 | 3.810618 | 0.269873 | 45.178349 | 00:26 | . 8 | 3.643807 | 3.611234 | 0.298628 | 37.011711 | 00:26 | . 9 | 3.452805 | 3.463478 | 0.321055 | 31.927832 | 00:26 | . 10 | 3.270783 | 3.327179 | 0.344084 | 27.859652 | 00:26 | . 11 | 3.163763 | 3.232886 | 0.359108 | 25.352715 | 00:26 | . 12 | 3.045434 | 3.159597 | 0.370843 | 23.561092 | 00:26 | . 13 | 2.966490 | 3.126066 | 0.377128 | 22.784180 | 00:26 | . 14 | 2.902631 | 3.073609 | 0.385408 | 21.619785 | 00:26 | . 15 | 2.820757 | 3.046120 | 0.389740 | 21.033569 | 00:26 | . 16 | 2.777062 | 3.038635 | 0.390358 | 20.876738 | 00:26 | . 17 | 2.769229 | 3.030882 | 0.392879 | 20.715488 | 00:26 | . 18 | 2.796158 | 3.030480 | 0.392528 | 20.707178 | 00:26 | . 19 | 2.793638 | 3.011434 | 0.396384 | 20.316509 | 00:26 | . 20 | 2.783323 | 3.030766 | 0.389189 | 20.713087 | 00:26 | . 21 | 2.814245 | 3.043278 | 0.392528 | 20.973883 | 00:26 | . 22 | 2.837232 | 3.032581 | 0.391360 | 20.750729 | 00:26 | . 23 | 2.936250 | 3.106416 | 0.380500 | 22.340832 | 00:26 | . 24 | 2.947105 | 3.058279 | 0.389131 | 21.290874 | 00:26 | . 25 | 2.898855 | 3.050217 | 0.388305 | 21.119930 | 00:26 | . 26 | 2.894289 | 3.040450 | 0.390124 | 20.914650 | 00:26 | . 27 | 2.872150 | 3.036854 | 0.391802 | 20.839584 | 00:26 | . 28 | 2.889433 | 3.027228 | 0.394306 | 20.639946 | 00:26 | . 29 | 2.867410 | 3.006690 | 0.397544 | 20.220360 | 00:26 | . 30 | 2.862009 | 3.016624 | 0.393505 | 20.422239 | 00:26 | . 31 | 2.810327 | 2.991279 | 0.399030 | 19.911135 | 00:26 | . 32 | 2.792699 | 2.978555 | 0.400232 | 19.659397 | 00:26 | . 33 | 2.754105 | 2.975938 | 0.403512 | 19.608009 | 00:26 | . 34 | 2.734813 | 2.960950 | 0.403996 | 19.316311 | 00:26 | . 35 | 2.723893 | 2.951143 | 0.405866 | 19.127806 | 00:26 | . 36 | 2.699175 | 2.936934 | 0.405415 | 18.857944 | 00:26 | . 37 | 2.665997 | 2.928869 | 0.409054 | 18.706461 | 00:26 | . 38 | 2.654328 | 2.930508 | 0.410215 | 18.737141 | 00:26 | . 39 | 2.636740 | 2.919134 | 0.410332 | 18.525244 | 00:26 | . 40 | 2.618056 | 2.898964 | 0.415306 | 18.155334 | 00:26 | . 41 | 2.591700 | 2.903557 | 0.415173 | 18.238911 | 00:26 | . 42 | 2.570820 | 2.898409 | 0.416867 | 18.145260 | 00:26 | . 43 | 2.565726 | 2.887301 | 0.418194 | 17.944815 | 00:26 | . 44 | 2.519047 | 2.891924 | 0.418954 | 18.027956 | 00:26 | . 45 | 2.512617 | 2.878029 | 0.422309 | 17.779202 | 00:26 | . 46 | 2.476611 | 2.871087 | 0.422760 | 17.656193 | 00:26 | . 47 | 2.476407 | 2.859713 | 0.424095 | 17.456518 | 00:26 | . 48 | 2.461777 | 2.860327 | 0.425197 | 17.467230 | 00:26 | . 49 | 2.427959 | 2.855028 | 0.427058 | 17.374922 | 00:26 | . 50 | 2.423167 | 2.854318 | 0.426950 | 17.362591 | 00:26 | . 51 | 2.403222 | 2.848868 | 0.428544 | 17.268225 | 00:26 | . 52 | 2.364372 | 2.843947 | 0.429779 | 17.183455 | 00:26 | . 53 | 2.362134 | 2.845242 | 0.429863 | 17.205723 | 00:26 | . 54 | 2.346170 | 2.838448 | 0.431757 | 17.089224 | 00:26 | . 55 | 2.329833 | 2.831658 | 0.433076 | 16.973577 | 00:26 | . 56 | 2.304311 | 2.836959 | 0.432409 | 17.063789 | 00:26 | . 57 | 2.300721 | 2.836190 | 0.434120 | 17.050686 | 00:26 | . 58 | 2.285471 | 2.830706 | 0.435555 | 16.957430 | 00:26 | . 59 | 2.256822 | 2.834683 | 0.434796 | 17.025009 | 00:26 | . 60 | 2.243629 | 2.833736 | 0.435964 | 17.008886 | 00:26 | . 61 | 2.218404 | 2.830714 | 0.437133 | 16.957567 | 00:29 | . 62 | 2.175385 | 2.835139 | 0.437784 | 17.032772 | 00:26 | . 63 | 2.158951 | 2.826954 | 0.436966 | 16.893930 | 00:26 | . 64 | 2.163277 | 2.830947 | 0.437759 | 16.961510 | 00:26 | . 65 | 2.142468 | 2.824928 | 0.439837 | 16.859735 | 00:26 | . 66 | 2.131182 | 2.832768 | 0.439620 | 16.992439 | 00:26 | . 67 | 2.105347 | 2.835190 | 0.440113 | 17.033638 | 00:26 | . 68 | 2.092000 | 2.836043 | 0.438911 | 17.048178 | 00:26 | . 69 | 2.090728 | 2.829720 | 0.441022 | 16.940714 | 00:26 | . 70 | 2.069707 | 2.839312 | 0.442299 | 17.104000 | 00:26 | . 71 | 2.044070 | 2.838725 | 0.442825 | 17.093950 | 00:26 | . 72 | 2.038418 | 2.836995 | 0.443359 | 17.064417 | 00:29 | . 73 | 2.028739 | 2.839885 | 0.442934 | 17.113806 | 00:26 | . 74 | 2.015540 | 2.840894 | 0.443176 | 17.131083 | 00:26 | . 75 | 1.994676 | 2.840110 | 0.444603 | 17.117641 | 00:26 | . 76 | 1.978677 | 2.847067 | 0.444061 | 17.237144 | 00:26 | . 77 | 1.965618 | 2.847578 | 0.443393 | 17.245958 | 00:26 | . 78 | 1.946630 | 2.845117 | 0.443985 | 17.203577 | 00:26 | . 79 | 1.955866 | 2.846086 | 0.444578 | 17.220251 | 00:26 | . 80 | 1.925109 | 2.845089 | 0.445646 | 17.203085 | 00:26 | . 81 | 1.920809 | 2.849102 | 0.445755 | 17.272268 | 00:26 | . 82 | 1.903838 | 2.847912 | 0.445763 | 17.251720 | 00:26 | . 83 | 1.906474 | 2.852767 | 0.446406 | 17.335674 | 00:26 | . 84 | 1.904742 | 2.848892 | 0.446080 | 17.268641 | 00:26 | . 85 | 1.904142 | 2.850545 | 0.446531 | 17.297205 | 00:26 | . 86 | 1.877277 | 2.851864 | 0.446239 | 17.320030 | 00:26 | . 87 | 1.874297 | 2.851761 | 0.446356 | 17.318247 | 00:26 | . 88 | 1.869577 | 2.852247 | 0.446481 | 17.326664 | 00:26 | . 89 | 1.859170 | 2.852836 | 0.446907 | 17.336874 | 00:26 | . 90 | 1.851207 | 2.854492 | 0.446556 | 17.365616 | 00:26 | . 91 | 1.852747 | 2.855567 | 0.446957 | 17.384291 | 00:26 | . 92 | 1.856752 | 2.856290 | 0.446907 | 17.396866 | 00:26 | . 93 | 1.838363 | 2.855285 | 0.446631 | 17.379396 | 00:26 | . 94 | 1.844568 | 2.856256 | 0.446957 | 17.396278 | 00:26 | . 95 | 1.836987 | 2.856410 | 0.446890 | 17.398949 | 00:26 | . 96 | 1.850361 | 2.856547 | 0.446815 | 17.401339 | 00:26 | . 97 | 1.855371 | 2.856554 | 0.446882 | 17.401455 | 00:26 | . 98 | 1.837600 | 2.856627 | 0.446890 | 17.402733 | 00:26 | . 99 | 1.841990 | 2.856612 | 0.446890 | 17.402472 | 00:26 | . learn.save(model_path/&#39;darija_lm_100&#39;) . Path(&#39;/content/drive/MyDrive/ml/projects/darija/models/darija_lm_100.pth&#39;) . def decoder(sentence): s = &#39;&#39;.join(sentence) return s.split(&#39;โ&#39;) . text = &#39;ุนูู ุญุณุจ ูุฅุญุตุงุก ูุนุงู&#39; n_words = 100 n_sentences = 2 preds = [learn.predict(text, n_words, temperature=0.75, decoder=decoder) for _ in range(n_sentences)] . preds . [&#39; xxbos ุนูู ุญุณุจ ูุฅุญุตุงุก ูุนุงู ุชุงุจุนุฉ ูููุธุงู ุฏูุงู ูุฅุณูุงู ููููุทูุฉ ูุญูุฑ ูููุง ุฑุจุนุง ููุณุชูููุงู ุฏูุงููุง ุดูุงู ุฅูุฑูููุง ูุฌุฒุงุฆุฑ ูุนุงุตูุฉ ุฏุฒุงูุฑ ุชููุณ ุฌููุจ ุดุฑูู ุฏูุงู ุชูุงุชุฉ ูููููู ูููู ููุจูุงุฏ ูู ูุนุงุตูุฉ ุฏูุงููุง ูู ูููุซุงู ุงููุบุฉ ุงูุฑุณููุฉ ููุจูุงุฏ ูููุง ุงููฃููุฒูุฉ ููุฑุงูุณุงููุฉ ูููฃููุฒูุฉ ููููุณ ุงููู ูุงุชุฎุฏ ูู ูููููู ุฃูฃ&#39;, &#39; xxbos ุนูู ุญุณุจ ูุฅุญุตุงุก ูุนุงู ุชุนููู ูุณุจุฉ ูุฃููุฉ ุงุณ ูุง ูุงูุนุฑููุด ููุฑุงู ููุง ููุชุจู ูุณุจุฉ ูุงู ูุงุฑููู ููู ุงููู ุชุงููู ุฌุงูุนุฉ ุงูุชุตุงุฏ ูุณุจุฉ ุงุณ ุดูุทูู ููุฏุฑู ูุฎุฏูู ูุณุจุฉ ูุจุทุงูุฉ ุงุณ ูุง ุฎุฏุงูููุด ุชุงูููุจู ุนูู ุฎุฏูุฉ ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ููุฉ ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ูุณุจุฉ ุงุณ ุงููู ุฎุฏุงููู ูู ููุทุงุน ูุฎุงุต ููุง ูุนุงุทููู ุงููู ุณุจู ููููู ุฎุฏูู ูุตุงุฏุฑ ุชุตููู ุฌูุฉ ุงูุดุฑู xxbos ูุดุงู ุงูุณููู ุฎูุงู ุฏุฌูุจุฑ ุชููุง ููุงูุฑู ูุบุฑุจู&#39;] .",
            "url": "https://issam9.github.io/ml-blog/2021/08/28/Darija-LM.html",
            "relUrl": "/2021/08/28/Darija-LM.html",
            "date": " โข Aug 28, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "A computer science student, passionate about machine learning, specifically deep learning. .",
          "url": "https://issam9.github.io/ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ โsitemap.xmlโ | absolute_url }} | .",
          "url": "https://issam9.github.io/ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}